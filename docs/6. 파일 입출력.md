
# 6. 파일 입출력

---

## 6.1 파일 입출력의 필요성

지금까지 작성한 프로그램들은 실행하는 동안만 데이터를 메모리에 저장했습니다. 프로그램을 종료하면 모든 변수와 계산 결과가 사라집니다. 다음에 다시 실행하면 처음부터 시작해야 합니다.

실용적인 프로그램이 되려면 데이터를 **영구적으로 저장**하고, 나중에 **다시 불러올** 수 있어야 합니다. 이것이 파일 입출력(File I/O, Input/Output)입니다.

**파일 입출력이 필요한 상황:**

- 사용자가 입력한 데이터를 저장 (설정, 기록, 점수 등)
- 큰 데이터셋을 분석 후 결과 보고서 생성
- 다른 프로그램이나 시스템과 데이터 공유
- 데이터베이스 없이 간단한 데이터 관리

**주요 파일 형식:**

- **텍스트 파일 (.txt):** 사람이 읽을 수 있는 평문
- **CSV (.csv):** 쉼표로 구분된 표 형식 데이터
- **JSON (.json):** 구조화된 데이터, 웹에서 널리 사용
- **Excel (.xlsx):** 스프레드시트 형식
- **바이너리 파일:** 이미지, 오디오, 압축 파일 등

**입출력 작업의 기본 흐름:**

1. 파일 열기 (open)
2. 데이터 읽기/쓰기 (read/write)
3. 파일 닫기 (close)

파일을 열면 운영체제는 리소스를 할당합니다. 작업 후 반드시 닫아야 리소스가 해제되고, 다른 프로그램이 파일에 접근할 수 있습니다.

---

## 6.2 텍스트 파일 다루기

### 6.2.1 파일 열기와 닫기

`open()` 함수로 파일을 엽니다.

```python
file = open('sample.txt', 'r')
# 파일 작업
file.close()
```

**파일 모드:**

|모드|의미|설명|
|---|---|---|
|'r'|Read|읽기 전용. 파일이 없으면 에러|
|'w'|Write|쓰기. 파일이 있으면 덮어씀 (기존 내용 삭제)|
|'a'|Append|추가. 파일 끝에 내용 추가|
|'x'|Exclusive|새 파일 생성. 이미 있으면 에러|
|'r+'|Read/Write|읽기와 쓰기|
|'b'|Binary|바이너리 모드 ('rb', 'wb' 등)|

**파일 경로:**

- **절대 경로:** 전체 경로 (`C:/Users/name/documents/file.txt`)
- **상대 경로:** 현재 작업 디렉터리 기준 (`./data/file.txt`, `../file.txt`)

```python
# 절대 경로
file = open('C:/Users/Alice/documents/data.txt', 'r')

# 상대 경로 (현재 디렉터리)
file = open('data.txt', 'r')

# 상대 경로 (하위 디렉터리)
file = open('data/sales.txt', 'r')
```

**파일 닫기의 중요성:**

```python
file = open('data.txt', 'r')
content = file.read()
file.close()  # 반드시 닫아야 함
```

닫지 않으면:

- 메모리 누수 발생 가능
- 다른 프로그램이 파일에 접근하지 못함
- 쓰기 작업이 디스크에 완전히 반영되지 않을 수 있음

### 6.2.2 with 문

`with` 문을 사용하면 파일이 자동으로 닫힙니다. **권장 패턴**입니다.

```python
with open('data.txt', 'r') as file:
    content = file.read()
    print(content)
# 여기서 파일이 자동으로 닫힘
```

**장점:**

- `close()`를 깜빡할 염려 없음
- 예외가 발생해도 자동으로 파일 닫힘
- 코드가 더 간결하고 안전

```python
# 나쁜 예
file = open('data.txt', 'r')
content = file.read()
# 여기서 에러 발생 시 close()가 실행 안 됨
file.close()

# 좋은 예
with open('data.txt', 'r') as file:
    content = file.read()
    # 에러가 나도 자동으로 닫힘
```

### 6.2.3 파일 읽기

**전체 읽기 (`.read()`):**

```python
with open('sample.txt', 'r') as file:
    content = file.read()
    print(content)
```

**한 줄씩 읽기 (`.readline()`):**

```python
with open('sample.txt', 'r') as file:
    line1 = file.readline()
    line2 = file.readline()
    print(line1)
    print(line2)
```

**모든 줄을 리스트로 (`.readlines()`):**

```python
with open('sample.txt', 'r') as file:
    lines = file.readlines()
    print(lines)  # ['첫 줄\n', '둘째 줄\n', '셋째 줄\n']
```

**반복문으로 읽기 (권장):**

메모리 효율적입니다. 큰 파일도 한 줄씩 처리할 수 있습니다.

```python
with open('sample.txt', 'r') as file:
    for line in file:
        print(line.strip())  # strip()으로 줄바꿈 제거
```

**실습: 텍스트 파일 생성 후 읽기**

```python
# 파일 생성
with open('memo.txt', 'w') as file:
    file.write("Python 공부 중\n")
    file.write("파일 입출력 배우는 중\n")
    file.write("재미있다!\n")

# 파일 읽기
with open('memo.txt', 'r') as file:
    content = file.read()
    print(content)
```

출력:

```
Python 공부 중
파일 입출력 배우는 중
재미있다!
```

### 6.2.4 파일 쓰기

**새 파일 쓰기 ('w' 모드):**

```python
with open('output.txt', 'w') as file:
    file.write("첫 번째 줄\n")
    file.write("두 번째 줄\n")
```

주의: 'w' 모드는 기존 파일을 **덮어씁니다**.

**추가 모드 ('a'):**

```python
with open('output.txt', 'a') as file:
    file.write("세 번째 줄\n")
```

기존 내용 뒤에 추가됩니다.

**여러 줄 쓰기 (`.writelines()`):**

```python
lines = [
    "Apple\n",
    "Banana\n",
    "Cherry\n"
]

with open('fruits.txt', 'w') as file:
    file.writelines(lines)
```

주의: `writelines()`는 자동으로 줄바꿈을 추가하지 않습니다. 직접 `\n`을 넣어야 합니다.

**리스트를 파일로 저장:**

```python
scores = [85, 92, 78, 90, 88]

with open('scores.txt', 'w') as file:
    for score in scores:
        file.write(f"{score}\n")
```

### 6.2.5 인코딩

**UTF-8의 중요성:**

한글이나 특수문자를 다룰 때는 인코딩을 명시해야 합니다.

```python
# 한글 쓰기
with open('korean.txt', 'w', encoding='utf-8') as file:
    file.write("안녕하세요\n")
    file.write("파이썬 프로그래밍\n")

# 한글 읽기
with open('korean.txt', 'r', encoding='utf-8') as file:
    content = file.read()
    print(content)
```

Windows에서는 기본 인코딩이 'cp949'여서 한글이 깨질 수 있습니다. **항상 `encoding='utf-8'`을 명시**하는 것이 좋습니다.

**인코딩 오류 처리:**

```python
# 잘못된 인코딩으로 읽을 때
with open('data.txt', 'r', encoding='utf-8', errors='ignore') as file:
    content = file.read()
```

`errors` 옵션:

- `'ignore'`: 오류 무시
- `'replace'`: 오류 문자를 ? 로 대체
- `'strict'`: 오류 발생 시 예외 (기본값)

---

## 6.3 CSV 파일

### 6.3.1 CSV 형식 이해

CSV(Comma-Separated Values)는 쉼표로 값을 구분하는 텍스트 파일입니다. 표 형태의 데이터를 저장하는 가장 간단한 방법입니다.

**예시:**

```
name,age,score
Alice,20,85
Bob,21,92
Charlie,19,78
```

**특징:**

- 첫 줄은 보통 헤더(열 이름)
- 각 줄은 하나의 레코드(행)
- 엑셀, 구글 스프레드시트에서 열고 편집 가능
- 크기가 작고 호환성이 좋음

### 6.3.2 csv 모듈

Python 표준 라이브러리에 포함되어 있습니다.

**읽기 (`csv.reader()`):**

```python
import csv

with open('students.csv', 'r', encoding='utf-8') as file:
    reader = csv.reader(file)
    
    for row in reader:
        print(row)
```

출력:

```
['name', 'age', 'score']
['Alice', '20', '85']
['Bob', '21', '92']
['Charlie', '19', '78']
```

**헤더 건너뛰기:**

```python
with open('students.csv', 'r', encoding='utf-8') as file:
    reader = csv.reader(file)
    header = next(reader)  # 첫 줄 건너뛰기
    
    for row in reader:
        name, age, score = row
        print(f"{name}: {score}점")
```

**쓰기 (`csv.writer()`):**

```python
import csv

data = [
    ['name', 'age', 'score'],
    ['Alice', 20, 85],
    ['Bob', 21, 92],
    ['Charlie', 19, 78]
]

with open('output.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerows(data)
```

주의: Windows에서는 `newline=''`을 지정해야 빈 줄이 생기지 않습니다.

**딕셔너리로 읽기 (`csv.DictReader()`):**

더 편리합니다.

```python
import csv

with open('students.csv', 'r', encoding='utf-8') as file:
    reader = csv.DictReader(file)
    
    for row in reader:
        print(f"{row['name']}: {row['score']}점")
```

출력:

```
Alice: 85점
Bob: 92점
Charlie: 78점
```

**딕셔너리로 쓰기 (`csv.DictWriter()`):**

```python
import csv

students = [
    {'name': 'Alice', 'age': 20, 'score': 85},
    {'name': 'Bob', 'age': 21, 'score': 92},
    {'name': 'Charlie', 'age': 19, 'score': 78}
]

with open('output.csv', 'w', newline='', encoding='utf-8') as file:
    fieldnames = ['name', 'age', 'score']
    writer = csv.DictWriter(file, fieldnames=fieldnames)
    
    writer.writeheader()  # 헤더 쓰기
    writer.writerows(students)
```

### 6.3.3 Pandas로 CSV 다루기

대부분의 경우 Pandas가 더 편리합니다.

**읽기:**

```python
import pandas as pd

df = pd.read_csv('students.csv')
print(df)
```

**옵션들:**

```python
# 특정 열만 읽기
df = pd.read_csv('students.csv', usecols=['name', 'score'])

# 헤더가 없는 경우
df = pd.read_csv('data.csv', header=None, names=['col1', 'col2', 'col3'])

# 구분자 변경 (탭으로 구분)
df = pd.read_csv('data.tsv', sep='\t')

# 특정 행 건너뛰기
df = pd.read_csv('data.csv', skiprows=[1, 2])

# 인코딩 지정
df = pd.read_csv('data.csv', encoding='cp949')
```

**쓰기:**

```python
df.to_csv('output.csv', index=False, encoding='utf-8')
```

옵션:

- `index=False`: 인덱스 열 제외
- `columns`: 특정 열만 저장
- `sep`: 구분자 변경

```python
# 특정 열만 저장
df.to_csv('output.csv', columns=['name', 'score'], index=False)

# 탭으로 구분
df.to_csv('output.tsv', sep='\t', index=False)
```

**AI 활용 팁:**

CSV 파싱 오류가 발생하면 AI에게 물어보세요.

"CSV 파일을 읽는데 ParserError가 발생합니다. 어떻게 해결하나요?"

```python
# 오류 예시
df = pd.read_csv('messy_data.csv')
# ParserError: Expected 3 fields in line 5, saw 4
```

AI가 제안할 수 있는 해결책:

- `error_bad_lines=False`로 오류 줄 건너뛰기
- `quoting` 옵션 조정
- 구분자 확인
- 파일 인코딩 확인

---

## 6.4 JSON 파일

### 6.4.1 JSON 형식

JSON(JavaScript Object Notation)은 데이터를 구조화해서 저장하는 텍스트 형식입니다. Python의 딕셔너리와 매우 유사합니다.

**예시:**

```json
{
  "name": "Alice",
  "age": 20,
  "scores": {
    "math": 85,
    "english": 92,
    "science": 78
  },
  "hobbies": ["reading", "swimming", "coding"]
}
```

**특징:**

- 사람이 읽고 쓰기 쉬움
- 대부분의 프로그래밍 언어에서 지원
- 웹 API에서 널리 사용
- 중첩 구조 표현 가능

**데이터 타입:**

- 객체: `{}`
- 배열: `[]`
- 문자열: `"..."`
- 숫자: `123`, `45.67`
- 불린: `true`, `false`
- null: `null`

### 6.4.2 json 모듈

**파일에서 읽기 (`json.load()`):**

```python
import json

with open('data.json', 'r', encoding='utf-8') as file:
    data = json.load(file)
    print(data)
    print(data['name'])
```

**문자열에서 읽기 (`json.loads()`):**

```python
import json

json_string = '{"name": "Alice", "age": 20, "score": 85}'
data = json.loads(json_string)
print(data)  # {'name': 'Alice', 'age': 20, 'score': 85}
```

**파일로 쓰기 (`json.dump()`):**

```python
import json

student = {
    "name": "Alice",
    "age": 20,
    "scores": {
        "math": 85,
        "english": 92,
        "science": 78
    }
}

with open('student.json', 'w', encoding='utf-8') as file:
    json.dump(student, file, ensure_ascii=False, indent=2)
```

**문자열로 변환 (`json.dumps()`):**

```python
json_string = json.dumps(student, ensure_ascii=False, indent=2)
print(json_string)
```

### 6.4.3 들여쓰기와 정렬

**`indent` 매개변수:**

가독성을 높입니다.

```python
# indent 없음 (한 줄)
json.dumps(student)
# '{"name": "Alice", "age": 20, "scores": {"math": 85, "english": 92, "science": 78}}'

# indent 있음 (보기 좋음)
json.dumps(student, indent=2)
```

출력:

```json
{
  "name": "Alice",
  "age": 20,
  "scores": {
    "math": 85,
    "english": 92,
    "science": 78
  }
}
```

**`sort_keys`:**

키를 알파벳 순으로 정렬합니다.

```python
json.dumps(student, indent=2, sort_keys=True)
```

**`ensure_ascii=False`:**

한글 등 비ASCII 문자를 유니코드 이스케이프 없이 저장합니다.

```python
data = {"이름": "앨리스", "나이": 20}

# ensure_ascii=True (기본값)
print(json.dumps(data))
# {"\uc774\ub984": "\uc568\ub9ac\uc2a4", "\ub098\uc774": 20}

# ensure_ascii=False
print(json.dumps(data, ensure_ascii=False))
# {"이름": "앨리스", "나이": 20}
```

**실습: 설정 파일 저장/불러오기**

```python
import json

# 설정 저장
config = {
    "username": "alice",
    "theme": "dark",
    "language": "ko",
    "notifications": True,
    "font_size": 14
}

with open('config.json', 'w', encoding='utf-8') as file:
    json.dump(config, file, ensure_ascii=False, indent=2)

# 설정 불러오기
with open('config.json', 'r', encoding='utf-8') as file:
    loaded_config = json.load(file)
    print(f"사용자: {loaded_config['username']}")
    print(f"테마: {loaded_config['theme']}")
    print(f"알림: {'켜짐' if loaded_config['notifications'] else '꺼짐'}")
```

---

## 6.5 Excel 파일

### 6.5.1 openpyxl과 xlsxwriter

Excel 파일(.xlsx)을 다루려면 외부 라이브러리가 필요합니다.

**설치:**

```bash
pip install openpyxl xlsxwriter
```

- **openpyxl:** 읽기와 쓰기 모두 가능
- **xlsxwriter:** 쓰기 전용, 더 많은 서식 기능

### 6.5.2 Pandas로 Excel 다루기

대부분의 경우 Pandas가 가장 편리합니다.

**읽기:**

```python
import pandas as pd

df = pd.read_excel('students.xlsx')
print(df)
```

**특정 시트 읽기:**

```python
# 첫 번째 시트 (기본값)
df = pd.read_excel('data.xlsx', sheet_name=0)

# 이름으로 지정
df = pd.read_excel('data.xlsx', sheet_name='성적')

# 여러 시트 읽기
dfs = pd.read_excel('data.xlsx', sheet_name=['시트1', '시트2'])
print(dfs['시트1'])
print(dfs['시트2'])

# 모든 시트 읽기
dfs = pd.read_excel('data.xlsx', sheet_name=None)
for sheet_name, df in dfs.items():
    print(f"\n{sheet_name}:")
    print(df)
```

**쓰기:**

```python
df.to_excel('output.xlsx', index=False, sheet_name='성적')
```

**여러 옵션:**

```python
df.to_excel(
    'output.xlsx',
    sheet_name='학생성적',
    index=False,
    startrow=2,      # 3번째 행부터 시작
    startcol=1       # B열부터 시작
)
```

### 6.5.3 ExcelWriter

여러 DataFrame을 한 파일의 다른 시트에 저장할 수 있습니다.

```python
import pandas as pd

# 데이터 준비
df_math = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie'],
    'score': [85, 92, 78]
})

df_english = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie'],
    'score': [90, 88, 95]
})

# 한 파일에 여러 시트로 저장
with pd.ExcelWriter('scores.xlsx', engine='openpyxl') as writer:
    df_math.to_excel(writer, sheet_name='수학', index=False)
    df_english.to_excel(writer, sheet_name='영어', index=False)
```

**기존 파일에 시트 추가:**

```python
with pd.ExcelWriter('scores.xlsx', engine='openpyxl', mode='a') as writer:
    df_science.to_excel(writer, sheet_name='과학', index=False)
```

---

## 6.6 경로 다루기

### 6.6.1 os 모듈

파일 시스템을 다루는 표준 라이브러리입니다.

**파일 존재 확인:**

```python
import os

if os.path.exists('data.txt'):
    print("파일이 존재합니다")
else:
    print("파일이 없습니다")
```

**디렉터리 확인:**

```python
if os.path.isdir('data'):
    print("디렉터리입니다")

if os.path.isfile('data.txt'):
    print("파일입니다")
```

**경로 결합:**

```python
# 올바른 방법
path = os.path.join('data', 'students', 'scores.csv')
print(path)  # Windows: data\students\scores.csv
             # Mac/Linux: data/students/scores.csv
```

슬래시를 직접 쓰는 것보다 `os.path.join()`을 사용하면 운영체제에 관계없이 올바른 경로를 만듭니다.

**경로 분리:**

```python
path = '/home/user/documents/data.csv'

dirname = os.path.dirname(path)
print(dirname)  # /home/user/documents

basename = os.path.basename(path)
print(basename)  # data.csv

# 확장자 분리
name, ext = os.path.splitext(basename)
print(name)  # data
print(ext)   # .csv
```

**디렉터리 목록:**

```python
files = os.listdir('.')  # 현재 디렉터리
print(files)

# CSV 파일만 필터링
csv_files = [f for f in files if f.endswith('.csv')]
```

**디렉터리 생성:**

```python
if not os.path.exists('output'):
    os.mkdir('output')  # 한 단계 디렉터리 생성

# 중간 디렉터리도 함께 생성
os.makedirs('output/data/processed', exist_ok=True)
```

### 6.6.2 pathlib 모듈 (권장)

Python 3.4부터 도입된 객체 지향 경로 라이브러리입니다. **현대적이고 직관적**입니다.

```python
from pathlib import Path

# Path 객체 생성
path = Path('data/students/scores.csv')

# 존재 확인
if path.exists():
    print("파일이 존재합니다")

# 디렉터리/파일 확인
print(path.is_file())
print(path.is_dir())

# 경로 결합 (/ 연산자 사용)
base_path = Path('data')
file_path = base_path / 'students' / 'scores.csv'
print(file_path)

# 부모 디렉터리
print(path.parent)       # data/students
print(path.parent.parent)  # data

# 파일명과 확장자
print(path.name)        # scores.csv
print(path.stem)        # scores
print(path.suffix)      # .csv

# 절대 경로
print(path.absolute())
```

**디렉터리 생성:**

```python
output_dir = Path('output/results')
output_dir.mkdir(parents=True, exist_ok=True)
```

**파일 목록:**

```python
data_dir = Path('data')

# 모든 파일
for file in data_dir.iterdir():
    print(file)

# CSV 파일만
for csv_file in data_dir.glob('*.csv'):
    print(csv_file)

# 재귀적으로 모든 CSV 파일
for csv_file in data_dir.rglob('*.csv'):
    print(csv_file)
```

**파일 읽기/쓰기:**

```python
path = Path('data.txt')

# 쓰기
path.write_text("Hello, World!", encoding='utf-8')

# 읽기
content = path.read_text(encoding='utf-8')
print(content)
```

**권장 사항:**

새 프로젝트에서는 `os.path` 대신 `pathlib`를 사용하세요. 더 직관적이고 에러가 적습니다.

---

## 6.7 예외 처리

### 6.7.1 파일 입출력 오류

파일 작업은 오류가 자주 발생합니다.

**`FileNotFoundError`:**

```python
with open('nonexistent.txt', 'r') as file:
    content = file.read()
# FileNotFoundError: [Errno 2] No such file or directory: 'nonexistent.txt'
```

**`PermissionError`:**

```python
# 읽기 전용 파일에 쓰기 시도
with open('readonly.txt', 'w') as file:
    file.write("data")
# PermissionError: [Errno 13] Permission denied: 'readonly.txt'
```

**`UnicodeDecodeError`:**

```python
# 잘못된 인코딩으로 읽기
with open('korean.txt', 'r', encoding='ascii') as file:
    content = file.read()
# UnicodeDecodeError: 'ascii' codec can't decode byte...
```

**`IsADirectoryError`:**

```python
with open('data/', 'r') as file:
    pass
# IsADirectoryError: [Errno 21] Is a directory: 'data/'
```

### 6.7.2 try-except 패턴

**기본 구조:**

```python
try:
    with open('data.txt', 'r') as file:
        content = file.read()
        print(content)
except FileNotFoundError:
    print("파일을 찾을 수 없습니다")
```

**여러 예외 처리:**

```python
try:
    with open('data.txt', 'r', encoding='utf-8') as file:
        data = file.read()
        number = int(data)
except FileNotFoundError:
    print("파일이 없습니다")
except ValueError:
    print("숫자로 변환할 수 없습니다")
except UnicodeDecodeError:
    print("인코딩 오류입니다")
```

**모든 예외 처리:**

```python
try:
    with open('data.txt', 'r') as file:
        content = file.read()
except Exception as e:
    print(f"오류 발생: {e}")
```

**`else`와 `finally`:**

```python
try:
    with open('data.txt', 'r') as file:
        content = file.read()
except FileNotFoundError:
    print("파일이 없습니다")
else:
    # 예외가 없을 때 실행
    print("파일을 성공적으로 읽었습니다")
finally:
    # 항상 실행
    print("작업 완료")
```

**안전한 파일 처리 패턴:**

```python
from pathlib import Path

def read_file_safely(filepath):
    """안전하게 파일을 읽는 함수"""
    path = Path(filepath)
    
    if not path.exists():
        print(f"오류: {filepath} 파일이 존재하지 않습니다")
        return None
    
    if not path.is_file():
        print(f"오류: {filepath}는 파일이 아닙니다")
        return None
    
    try:
        with open(path, 'r', encoding='utf-8') as file:
            return file.read()
    except PermissionError:
        print(f"오류: {filepath}에 접근 권한이 없습니다")
        return None
    except UnicodeDecodeError:
        print(f"오류: {filepath}의 인코딩이 올바르지 않습니다")
        return None
    except Exception as e:
        print(f"예상치 못한 오류: {e}")
        return None

# 사용
content = read_file_safely('data.txt')
if content:
    print(content)
```

### 6.7.3 사용자 정의 예외

특정 상황에 맞는 예외를 만들 수 있습니다.

```python
class InvalidDataFormatError(Exception):
    """데이터 형식이 올바르지 않을 때"""
    pass

def load_scores(filepath):
    """점수 파일 읽기"""
    with open(filepath, 'r') as file:
        for line in file:
            parts = line.strip().split(',')
            if len(parts) != 2:
                raise InvalidDataFormatError(
                    f"잘못된 형식: {line.strip()}"
                )
            name, score = parts
            if not score.isdigit():
                raise InvalidDataFormatError(
                    f"점수가 숫자가 아닙니다: {score}"
                )
    return True

try:
    load_scores('scores.txt')
except InvalidDataFormatError as e:
    print(f"데이터 오류: {e}")
except FileNotFoundError:
    print("파일을 찾을 수 없습니다")
```

---

## 6.8 실습: 데이터 파이프라인

### 6.8.1 요구사항

실제 데이터 분석 프로젝트의 전체 흐름을 구현해봅시다.

1. 여러 CSV 파일에서 데이터 수집
2. 데이터 병합 및 정제
3. 분석 수행
4. 결과를 다양한 형식으로 저장 (CSV, JSON, Excel)
5. 작업 로그 기록

### 6.8.2 파이프라인 구축

**1단계: 샘플 데이터 생성**

```python
import pandas as pd
import numpy as np
from pathlib import Path

# 출력 디렉터리 생성
Path('data').mkdir(exist_ok=True)

# 3개월치 매출 데이터 생성
np.random.seed(42)

months = ['january', 'february', 'march']

for month in months:
    data = {
        'date': pd.date_range(f'2024-{months.index(month)+1}-01', periods=10),
        'product': np.random.choice(['A', 'B', 'C'], 10),
        'quantity': np.random.randint(1, 20, 10),
        'price': np.random.randint(1000, 5000, 10)
    }
    
    df = pd.DataFrame(data)
    df.to_csv(f'data/sales_{month}.csv', index=False)
    print(f"{month} 데이터 생성 완료")
```

**2단계: 데이터 파이프라인**

```python
import pandas as pd
import json
from pathlib import Path
from datetime import datetime

class SalesDataPipeline:
    """매출 데이터 처리 파이프라인"""
    
    def __init__(self, data_dir='data', output_dir='output'):
        self.data_dir = Path(data_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.log = []  # 작업 로그
        self.data = None
    
    def log_message(self, message):
        """로그 메시지 기록"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_entry = f"[{timestamp}] {message}"
        self.log.append(log_entry)
        print(log_entry)
    
    def load_data(self):
        """모든 CSV 파일 불러오기"""
        self.log_message("데이터 로드 시작")
        
        csv_files = list(self.data_dir.glob('sales_*.csv'))
        
        if not csv_files:
            self.log_message("오류: CSV 파일을 찾을 수 없습니다")
            return False
        
        dfs = []
        
        for file in csv_files:
            try:
                df = pd.read_csv(file)
                dfs.append(df)
                self.log_message(f"{file.name} 로드 완료 ({len(df)} rows)")
            except Exception as e:
                self.log_message(f"오류: {file.name} 로드 실패 - {e}")
                return False
        
        self.data = pd.concat(dfs, ignore_index=True)
        self.log_message(f"총 {len(self.data)} 레코드 병합 완료")
        return True
    
    def clean_data(self):
        """데이터 정제"""
        self.log_message("데이터 정제 시작")
        
        # 날짜 형식 변환
        self.data['date'] = pd.to_datetime(self.data['date'])
        
        # 매출액 계산
        self.data['revenue'] = self.data['quantity'] * self.data['price']
        
        # 결측치 확인
        missing = self.data.isna().sum()
        if missing.any():
            self.log_message(f"결측치 발견: {missing[missing > 0].to_dict()}")
        else:
            self.log_message("결측치 없음")
        
        self.log_message("데이터 정제 완료")
    
    def analyze(self):
        """데이터 분석"""
        self.log_message("분석 시작")
        
        # 전체 통계
        total_revenue = self.data['revenue'].sum()
        total_quantity = self.data['quantity'].sum()
        avg_price = self.data['price'].mean()
        
        # 제품별 통계
        product_stats = self.data.groupby('product').agg({
            'quantity': 'sum',
            'revenue': 'sum'
        }).reset_index()
        
        # 월별 통계
        self.data['month'] = self.data['date'].dt.month
        monthly_stats = self.data.groupby('month').agg({
            'revenue': 'sum',
            'quantity': 'sum'
        }).reset_index()
        
        results = {
            'summary': {
                'total_revenue': float(total_revenue),
                'total_quantity': int(total_quantity),
                'average_price': float(avg_price)
            },
            'by_product': product_stats.to_dict('records'),
            'by_month': monthly_stats.to_dict('records')
        }
        
        self.log_message(f"총 매출: {total_revenue:,.0f}원")
        self.log_message(f"총 판매량: {total_quantity:,}개")
        
        return results
    
    def save_results(self, results):
        """결과 저장"""
        self.log_message("결과 저장 시작")
        
        # 1. CSV로 저장
        self.data.to_csv(
            self.output_dir / 'sales_complete.csv',
            index=False,
            encoding='utf-8'
        )
        self.log_message("CSV 저장 완료")
        
        # 2. JSON으로 저장
        with open(self.output_dir / 'analysis_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        self.log_message("JSON 저장 완료")
        
        # 3. Excel로 저장 (여러 시트)
        with pd.ExcelWriter(
            self.output_dir / 'sales_report.xlsx',
            engine='openpyxl'
        ) as writer:
            self.data.to_excel(writer, sheet_name='전체데이터', index=False)
            
            pd.DataFrame(results['by_product']).to_excel(
                writer, sheet_name='제품별', index=False
            )
            
            pd.DataFrame(results['by_month']).to_excel(
                writer, sheet_name='월별', index=False
            )
        
        self.log_message("Excel 저장 완료")
        
        # 4. 로그 저장
        with open(self.output_dir / 'pipeline.log', 'w', encoding='utf-8') as f:
            f.write('\n'.join(self.log))
        self.log_message("로그 저장 완료")
    
    def run(self):
        """전체 파이프라인 실행"""
        print("=" * 70)
        print("매출 데이터 처리 파이프라인")
        print("=" * 70)
        
        if not self.load_data():
            return False
        
        self.clean_data()
        results = self.analyze()
        self.save_results(results)
        
        print("=" * 70)
        self.log_message("파이프라인 실행 완료")
        print("=" * 70)
        
        return True


# 실행
if __name__ == '__main__':
    pipeline = SalesDataPipeline()
    pipeline.run()
```

실행 결과:

```
======================================================================
매출 데이터 처리 파이프라인
======================================================================
[2026-02-14 15:30:00] 데이터 로드 시작
[2026-02-14 15:30:00] sales_january.csv 로드 완료 (10 rows)
[2026-02-14 15:30:00] sales_february.csv 로드 완료 (10 rows)
[2026-02-14 15:30:00] sales_march.csv 로드 완료 (10 rows)
[2026-02-14 15:30:00] 총 30 레코드 병합 완료
[2026-02-14 15:30:00] 데이터 정제 시작
[2026-02-14 15:30:00] 결측치 없음
[2026-02-14 15:30:00] 데이터 정제 완료
[2026-02-14 15:30:00] 분석 시작
[2026-02-14 15:30:00] 총 매출: 853,000원
[2026-02-14 15:30:00] 총 판매량: 287개
[2026-02-14 15:30:00] 결과 저장 시작
[2026-02-14 15:30:00] CSV 저장 완료
[2026-02-14 15:30:00] JSON 저장 완료
[2026-02-14 15:30:00] Excel 저장 완료
[2026-02-14 15:30:00] 로그 저장 완료
======================================================================
[2026-02-14 15:30:00] 파이프라인 실행 완료
======================================================================
```

### 6.8.3 로깅

더 체계적인 로깅을 위해 Python의 `logging` 모듈을 사용할 수 있습니다.

```python
import logging

# 로깅 설정
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('pipeline.log', encoding='utf-8'),
        logging.StreamHandler()  # 콘솔에도 출력
    ]
)

logger = logging.getLogger(__name__)

# 사용
logger.info("데이터 로드 시작")
logger.warning("결측치 발견")
logger.error("파일을 찾을 수 없습니다")
```

**AI 활용 팁:**

파이프라인을 최적화하고 싶다면 AI에게 물어보세요.

"이 데이터 파이프라인의 성능을 개선하려면 어떻게 해야 하나요?"

AI가 제안할 수 있는 개선사항:

- 병렬 처리로 파일 로드 속도 향상
- 청크 단위로 큰 파일 처리
- 캐싱으로 중복 작업 방지
- 프로그레스 바 추가
- 에러 복구 메커니즘

---

**이 장에서 배운 것:**

- **파일 입출력 기초:** `open()`, `with` 문, 읽기/쓰기 모드
- **텍스트 파일:** `.read()`, `.readline()`, `.readlines()`, `.write()`
- **CSV:** `csv` 모듈과 Pandas로 읽기/쓰기
- **JSON:** 구조화된 데이터 저장, `json.load()`, `json.dump()`
- **Excel:** Pandas로 xlsx 파일 다루기, 여러 시트 처리
- **경로 관리:** `os.path`와 `pathlib`, 파일 시스템 탐색
- **예외 처리:** try-except, 안전한 파일 처리 패턴
- **실습:** 완전한 데이터 파이프라인 구축

